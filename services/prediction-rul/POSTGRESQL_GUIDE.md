# Guide PostgreSQL - Service Prediction RUL

## Vue d'ensemble

Le service `prediction-rul` utilise PostgreSQL pour journaliser toutes les pr√©dictions RUL, permettant l'historique, l'analyse et le reporting.

## ‚ö†Ô∏è Instructions obligatoires

### 1. Cr√©er la base de donn√©es PostgreSQL (OBLIGATOIRE)

**Tu dois ex√©cuter ces commandes SQL une seule fois** pour cr√©er la base de donn√©es et l'utilisateur :

```sql
CREATE DATABASE predictive_maintenance;
CREATE USER pmuser WITH PASSWORD 'pmpassword';
GRANT ALL PRIVILEGES ON DATABASE predictive_maintenance TO pmuser;
```

**Comment faire :**
- Connecte-toi √† PostgreSQL (via `psql` ou un client graphique)
- Ex√©cute les 3 commandes SQL ci-dessus
- C'est tout ! Le service cr√©era automatiquement les tables au d√©marrage

### 2. Configurer les variables d'environnement (OBLIGATOIRE)

**Tu dois configurer ces variables** dans ton fichier `.env` ou comme variables d'environnement :

```bash
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=predictive_maintenance
DATABASE_USER=pmuser
DATABASE_PASSWORD=pmpassword
```

**C'est tout pour la configuration obligatoire !** Le service cr√©era automatiquement les tables et index au d√©marrage.

## üìã Instructions optionnelles (pour r√©f√©rence)

Les sections suivantes sont des **exemples et guides de r√©f√©rence** - tu n'as pas besoin de les ex√©cuter maintenant :

## Structure de la table (cr√©√©e automatiquement)

**‚ö†Ô∏è Tu n'as RIEN √† faire ici** - La table `rul_predictions` est cr√©√©e automatiquement au d√©marrage du service :

```sql
CREATE TABLE rul_predictions (
    id SERIAL PRIMARY KEY,
    asset_id VARCHAR(255) NOT NULL,
    sensor_id VARCHAR(255),
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    rul_prediction DECIMAL(10, 2) NOT NULL,
    confidence_interval_lower DECIMAL(10, 2),
    confidence_interval_upper DECIMAL(10, 2),
    confidence_level DECIMAL(3, 2) DEFAULT 0.95,
    uncertainty DECIMAL(10, 2),
    model_used VARCHAR(50) NOT NULL,
    model_scores JSONB,
    features JSONB NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

### Index

Les index suivants sont cr√©√©s automatiquement pour optimiser les requ√™tes :

- `idx_rul_asset_id` - Sur `asset_id`
- `idx_rul_sensor_id` - Sur `sensor_id`
- `idx_rul_timestamp` - Sur `timestamp`
- `idx_rul_model_used` - Sur `model_used`
- `idx_rul_asset_timestamp` - Composite sur `(asset_id, timestamp DESC)`
- `idx_rul_sensor_timestamp` - Composite sur `(sensor_id, timestamp DESC)`

## Journalisation automatique (fonctionne automatiquement)

**‚ö†Ô∏è Tu n'as RIEN √† faire ici** - La journalisation fonctionne automatiquement :

- **Via l'API REST** : Les pr√©dictions RUL via `POST /api/v1/rul/predict` sont automatiquement journalis√©es
- **Via le Worker Kafka** : Le worker Kafka journalise automatiquement toutes les pr√©dictions RUL en temps-r√©el

## API REST

### GET /api/v1/rul/

R√©cup√®re l'historique des pr√©dictions RUL avec filtres et pagination :

```bash
# Toutes les pr√©dictions
curl http://localhost:8085/api/v1/rul/

# Filtrer par asset_id
curl "http://localhost:8085/api/v1/rul/?asset_id=ASSET001"

# Filtrer par mod√®le utilis√©
curl "http://localhost:8085/api/v1/rul/?model_used=lstm"

# Avec pagination
curl "http://localhost:8085/api/v1/rul/?limit=50&offset=0"

# Avec dates
curl "http://localhost:8085/api/v1/rul/?start_date=2024-01-01T00:00:00Z&end_date=2024-01-31T23:59:59Z"
```

**R√©ponse :**
```json
{
    "predictions": [
        {
            "id": 1,
            "asset_id": "ASSET001",
            "sensor_id": "SENSOR001",
            "timestamp": "2024-01-15T10:30:00Z",
            "rul_prediction": 150.5,
            "confidence_interval_lower": 140.0,
            "confidence_interval_upper": 160.0,
            "confidence_level": 0.95,
            "uncertainty": 10.0,
            "model_used": "ensemble",
            "model_scores": {"lstm": 150.0, "gru": 151.0},
            "features": {"rms": 10.5, "kurtosis": 2.3},
            "metadata": {}
        }
    ],
    "total": 1,
    "limit": 100,
    "offset": 0,
    "filters": {
        "asset_id": null,
        "sensor_id": null,
        "start_date": null,
        "end_date": null,
        "model_used": null
    }
}
```

## Requ√™tes SQL utiles

### Compter les pr√©dictions par actif

```sql
SELECT asset_id, COUNT(*) as prediction_count
FROM rul_predictions
GROUP BY asset_id
ORDER BY prediction_count DESC;
```

### Derni√®re pr√©diction pour chaque actif

```sql
SELECT DISTINCT ON (asset_id)
    asset_id, rul_prediction, timestamp, model_used
FROM rul_predictions
ORDER BY asset_id, timestamp DESC;
```

### Pr√©dictions avec faible RUL (< 50 cycles)

```sql
SELECT asset_id, rul_prediction, timestamp, model_used
FROM rul_predictions
WHERE rul_prediction < 50
ORDER BY rul_prediction ASC, timestamp DESC;
```

### √âvolution de la RUL pour un actif

```sql
SELECT timestamp, rul_prediction, confidence_interval_lower, confidence_interval_upper
FROM rul_predictions
WHERE asset_id = 'ASSET001'
ORDER BY timestamp ASC;
```

## Performance

### Optimisations automatiques

- **Index automatiques** : Tous les index n√©cessaires sont cr√©√©s automatiquement
- **Pool de connexions** : Gestion automatique du pool (1-10 connexions)
- **JSONB** : Utilisation de JSONB pour les champs complexes (scores, features, metadata)

### Recommandations

- **Archivage** : Consid√©rer l'archivage des anciennes pr√©dictions (> 1 an)
- **Partitioning** : Pour de tr√®s grandes tables, consid√©rer le partitioning par date
- **TimescaleDB** : Pour des performances optimales avec des donn√©es temporelles, consid√©rer TimescaleDB

## Troubleshooting

### Erreur de connexion

```
Erreur lors de l'initialisation du pool PostgreSQL: ...
```

**Solution :**
1. V√©rifier que PostgreSQL est d√©marr√©
2. V√©rifier les credentials dans `.env`
3. V√©rifier que la base de donn√©es existe

### Table n'existe pas

```
relation "rul_predictions" does not exist
```

**Solution :**
- Le service devrait cr√©er la table automatiquement au d√©marrage
- V√©rifier les logs pour les erreurs de cr√©ation
- V√©rifier les permissions de l'utilisateur PostgreSQL

### Erreur de journalisation

Si la journalisation √©choue, le service continue de fonctionner (les pr√©dictions sont toujours retourn√©es, mais non journalis√©es).

**V√©rifier les logs :**
```bash
# Chercher les erreurs PostgreSQL dans les logs
grep -i "postgresql\|database" logs/app.log
```

## Maintenance

### Sauvegarde

```bash
# Sauvegarder la base de donn√©es
pg_dump -U pmuser -d predictive_maintenance > backup.sql

# Restaurer
psql -U pmuser -d predictive_maintenance < backup.sql
```

### Nettoyage des anciennes donn√©es

```sql
-- Supprimer les pr√©dictions de plus d'1 an
DELETE FROM rul_predictions
WHERE timestamp < NOW() - INTERVAL '1 year';
```

### Statistiques

```sql
-- Statistiques g√©n√©rales
SELECT 
    COUNT(*) as total_predictions,
    COUNT(DISTINCT asset_id) as unique_assets,
    AVG(rul_prediction) as avg_rul,
    MIN(rul_prediction) as min_rul,
    MAX(rul_prediction) as max_rul
FROM rul_predictions;
```

